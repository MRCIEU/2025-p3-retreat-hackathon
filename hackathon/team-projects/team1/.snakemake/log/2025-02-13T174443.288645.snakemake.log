host: T9922TPW6L
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job              count
-------------  -------
download_data        1
targets              1
total                2

Select jobs to execute...
Execute 1 jobs...

[Thu Feb 13 17:44:43 2025]
localrule download_data:
    input: code/s01_download_data.sh
    output: data/raw
    jobid: 1
    reason: Updated input files: code/s01_download_data.sh
    resources: tmpdir=/var/folders/yr/b1g0zhl91gg99q69m79d2h340000gq/T

[Thu Feb 13 17:44:45 2025]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...

[Thu Feb 13 17:44:45 2025]
localrule targets:
    input: data/raw
    jobid: 0
    reason: Input files updated by another job: data/raw
    resources: tmpdir=/var/folders/yr/b1g0zhl91gg99q69m79d2h340000gq/T

[Thu Feb 13 17:44:45 2025]
Finished job 0.
2 of 2 steps (100%) done
Complete log: .snakemake/log/2025-02-13T174443.288645.snakemake.log
